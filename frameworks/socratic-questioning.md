# Socratic Questioning Framework for Idea Validation

This framework helps validate ideas through targeted, thoughtful questioning. Use this to guide founders and product teams from vague concepts to clear, well-reasoned business opportunities.

---

## Core Philosophy

**The goal is NOT to challenge the founder, but to help them think more clearly.**

Good Socratic questioning:
- ✅ Helps uncover assumptions
- ✅ Clarifies fuzzy thinking
- ✅ Surfaces potential issues early
- ✅ Strengthens the business case

Bad Socratic questioning:
- ❌ Feels like an interrogation
- ❌ Makes founder defensive
- ❌ Asks "gotcha" questions
- ❌ Questions just to question

---

## The Five Question Categories

Use 3-5 questions per validation area. Pick the most relevant from each category based on the idea.

### 1. Problem Clarity Questions

**Purpose:** Ensure the problem is real and well-understood

**Questions to ask:**

**"What specific pain point does this solve?"**
- Look for concrete examples, not abstract statements
- Good: "Sales teams waste 3 hours daily manually updating CRM from email threads"
- Bad: "Businesses need better productivity tools"

**"How do we know this is a real problem?"**
- Push for evidence: user interviews, personal experience, industry reports, observed behavior
- Qualitative + quantitative is strongest

**"Who experiences this problem most acutely?"**
- Forces specificity about target customers
- Helps prioritize if you can't solve for everyone

**"What's the cost of NOT solving this?"**
- Revenue loss? Time waste? Competitive disadvantage? Risk exposure?
- Helps establish urgency and willingness to pay

**"What do people do today when they have this problem?"**
- Reveals existing alternatives and workarounds
- Shows what you're competing against (even if it's manual processes)

---

### 2. Solution Validation Questions

**Purpose:** Ensure the proposed solution actually solves the problem

**Questions to ask:**

**"Why is this the right solution for that problem?"**
- Look for logical connection between problem and solution
- Watch for solutions looking for problems

**"What alternatives did you consider? Why did you reject them?"**
- Shows depth of thinking
- Reveals trade-offs that were considered
- "This is the only way" is a red flag

**"What's the simplest version that solves the core problem?"**
- Helps avoid over-engineering
- Identifies must-have vs nice-to-have

**"How will customers discover this solution?"**
- Great product that no one finds is useless
- Tests go-to-market thinking early

**"What would need to be true for this solution to work?"**
- Surfaces critical assumptions
- Identifies dependencies and risks

---

### 3. Success Criteria Questions

**Purpose:** Ensure we can measure if the solution works

**Questions to ask:**

**"How will we know if this idea is successful?"**
- Look for specific, measurable outcomes
- Both quantitative (metrics) and qualitative (feedback) matter

**"What would make you consider this idea a failure?"**
- Helps identify risks and edge cases
- Good founders have clear failure criteria

**"What metric are we trying to move? By how much?"**
- Forces specificity
- "Get more users" → "Reach 1,000 paying customers in first year"

**"What's the adoption target for first 6 months?"**
- Not all products need mass-market adoption immediately
- Different targets for different customer segments
- Helps set realistic expectations

**"What customer behavior change are we looking for?"**
- Beyond vanity metrics, what actual behavior shifts?
- "Users log in daily" vs "Users reduce manual work by 50%"

---

### 4. Constraint & Trade-off Questions

**Purpose:** Surface limitations and difficult decisions

**Questions to ask:**

**"What are the technical or operational constraints?"**
- Helps identify realistic implementation challenges
- Surfaces blockers early (regulations, integrations, infrastructure)

**"What are we NOT going to do as part of the MVP?"**
- Scope management is critical
- Clear non-goals prevent feature creep

**"What existing solutions or workflows does this disrupt?"**
- Nothing exists in isolation
- Need to think about adoption barriers and change management

**"If you had half the resources, what would you cut?"**
- Reveals true priorities
- Helps identify MVP vs full vision

**"What would you need to believe to 10x the price?"**
- Tests understanding of value vs cost
- Reveals what drives premium pricing

---

### 5. Strategic Fit Questions

**Purpose:** Ensure idea aligns with market opportunity and founder capabilities

**Questions to ask:**

**"Why is this the right idea to pursue RIGHT NOW?"**
- Tests urgency and market timing
- Helps clarify opportunity cost

**"Why are you uniquely positioned to build this?"**
- Unfair advantage: domain expertise, network, technology, distribution
- Helps tell the "why us" story

**"What happens if you wait 6 months to build this?"**
- Tests true urgency vs perceived urgency
- Helps prioritize against other opportunities

**"How does this idea change in a best-case vs worst-case scenario?"**
- Tests resilience of the business model
- Identifies what needs to be true for various outcomes

**"What would make this a billion-dollar business vs a million-dollar business?"**
- Tests scalability thinking
- Reveals whether founder is thinking big enough (or too big)

---

## Conversation Flow Tips

### Start Broad, Then Narrow

**First questions:** Problem clarity + who experiences it
**Middle questions:** Solution validation + success criteria
**Last questions:** Strategic fit + constraints

This helps founders start from customer needs and work up to business strategy, not the reverse.

### Listen for Red Flags

**Vague language:**
- "People want better..." → What specifically? Who?
- "This will improve..." → Improve what, by how much?
- "Everyone needs..." → Really? Everyone? Be specific.

**Solution-first thinking:**
- Founder can describe product but struggles to describe problem
- "Because competitors are doing it" is not a problem statement

**Lack of evidence:**
- "I think customers would pay..." → How do we know?
- No data, no customer conversations, no examples
- Only anecdotes, no pattern

**Unclear success:**
- Can't articulate what success looks like
- No metrics, no timeline, no qualitative indicators

**Unfounded optimism:**
- "We'll capture 1% of a huge market" (without explaining how)
- "It's a $50B market" (without defining TAM/SAM/SOM)
- "Once we build it, they will come" (no distribution strategy)

---

## Example Question Sequence

**For an AI-Powered Sales Email Automation Tool:**

1. **Problem:** "What specific problem in sales outreach does this solve? What do salespeople struggle with today?"
   - Pushes for concrete problem statement with evidence

2. **Solution:** "Why AI automation over hiring more SDRs or using existing tools? What alternatives did you consider?"
   - Tests solution validation and differentiation

3. **Success:** "How will we measure if sales teams actually adopt this? What behavior change are we looking for?"
   - Establishes clear success criteria (beyond vanity metrics)

4. **Constraints:** "What are we NOT including in the MVP? What capabilities come in V2 or V3?"
   - Helps scope the initial product
   - Identifies what's core vs nice-to-have

5. **Strategic Fit:** "Why is now the right time for this? What's changed in the market or technology that makes this possible?"
   - Tests market timing and strategic thinking

---

## Coaching Notes

**If founder struggles with a question:**
- Don't leave them hanging
- Offer multiple-choice options or examples
- Share comparable examples from other contexts
- This is a learning tool, not a test

**If founder gives weak answer:**
- Ask follow-up: "Can you say more about that?"
- Probe gently: "What evidence supports that assumption?"
- Offer alternative perspective: "Some might argue X, how would you respond?"
- Suggest research: "Would it help to look up market data on this?"

**If founder gives great answer:**
- Acknowledge it!
- Build on it with next question
- Show how their answer strengthens the business case
- Use it to probe deeper: "That's specific. How did you learn that?"

**If founder says "I don't know":**
- Decide: Can they estimate? Should they research? Is it acceptable to mark as "TBD"?
- Offer to research if it's market data, industry benchmarks, competitor info
- Don't let them skip critical assumptions - mark for validation

---

## Output Goal

After Socratic questioning, founder should have:

✅ Clear, specific problem statement with evidence
✅ Rational justification for why THIS solution
✅ Concrete success criteria (quantitative + qualitative)
✅ Explicit scope boundaries (what's in, what's out)
✅ Strategic narrative for why this opportunity matters now
✅ List of riskiest assumptions that need validation
✅ Understanding of what evidence still needs to be gathered

These answers form the foundation of a strong Lean Canvas or SVPG Opportunity Assessment.

---

## Integration with Validation Frameworks

### For Lean Canvas:

| Lean Canvas Section | Primary Socratic Category | Key Questions |
|---------------------|---------------------------|---------------|
| Problem | Problem Clarity | What specific pain? Who has it? How do you know? |
| Customer Segments | Problem Clarity + Strategic Fit | Who most acutely? How reachable? Why you? |
| Unique Value Proposition | Solution Validation | Why this solution? What alternatives exist? |
| Solution | Solution Validation + Constraints | Simplest version? What's not included? |
| Channels | Solution Validation | How will they discover it? |
| Revenue Streams | Success Criteria + Constraints | What would you pay? What drives 10x price? |
| Cost Structure | Constraints | What are key costs? Unit economics? |
| Key Metrics | Success Criteria | What metric matters? What's the target? |
| Unfair Advantage | Strategic Fit | Why you? Why now? What's unique? |

### For SVPG Opportunity Assessment:

| SVPG Question | Primary Socratic Category | Enhanced Questions |
|---------------|---------------------------|-------------------|
| What problem? | Problem Clarity | Specific pain? Evidence? Cost of not solving? |
| For whom? | Problem Clarity | Who most acutely? How many? How reachable? |
| How big? | Success Criteria + Strategic Fit | TAM/SAM/SOM? What would make this huge? |
| What alternatives? | Solution Validation | What exists today? Why not good enough? |
| Why us? | Strategic Fit | Unfair advantage? Unique positioning? |
| Why now? | Strategic Fit | What's changed? What if we wait? |
| How to reach? | Solution Validation | Discovery? Channels? Distribution? |
| Success metrics? | Success Criteria | What metric? What target? What behavior change? |
| What must go right? | Constraints | Critical assumptions? Dependencies? |
| What risks? | Constraints | Value? Usability? Feasibility? Viability? |

---

## Conversation Patterns

### Pattern 1: The Probe
**When to use:** Answer is vague or generic

```
Founder: "It helps businesses be more productive."
Agent: "What specific productivity problem? Can you give an example?"
Founder: "Well, sales teams waste time on admin work."
Agent: "What admin work specifically? How much time?"
```

### Pattern 2: The Evidence Check
**When to use:** Claim lacks supporting data

```
Founder: "Companies will pay $500/month for this."
Agent: "How do you know? Have you talked to potential customers about pricing?"
Founder: "Not yet, but similar tools charge that."
Agent: "Which tools? How are they similar? Should we research their pricing?"
```

### Pattern 3: The Alternative Exploration
**When to use:** Solution seems like the only option considered

```
Founder: "We'll build a mobile app."
Agent: "Why mobile over web? What alternatives did you consider?"
Founder: "Everyone uses mobile now."
Agent: "True for some use cases. What's your user's context when they need this?"
```

### Pattern 4: The Constraint Test
**When to use:** Scope seems too broad

```
Founder: "We'll have AI, automation, analytics, and integrations."
Agent: "What's the simplest version that solves the core problem?"
Founder: "Probably just the automation part."
Agent: "What would you cut if you had half the time?"
```

### Pattern 5: The Strategic Challenge
**When to use:** Urgency or timing is unclear

```
Founder: "This is a huge opportunity."
Agent: "Why is now the right time? What happens if you wait 6 months?"
Founder: "Competitors might move first."
Agent: "What competitive advantage do you lose? What do you gain by waiting?"
```

---

## Quality Thresholds

Before advancing from questioning to canvas generation, ensure:

**Problem Clarity:**
- ✅ Specific, concrete problem stated (not abstract)
- ✅ Evidence provided (user interviews, data, observation, personal experience)
- ✅ Target customer clearly defined (role, industry, size, context)

**Solution Validation:**
- ✅ Logical connection between problem and solution
- ✅ Alternatives considered and reasons for rejection documented
- ✅ MVP scope defined (what's in, what's out)

**Success Criteria:**
- ✅ Quantitative metric identified with target (e.g., "1,000 paying customers in 12 months")
- ✅ Qualitative success indicators defined (e.g., "customers use daily without prompting")
- ✅ Failure criteria articulated

**Strategic Fit:**
- ✅ Market timing justified ("why now")
- ✅ Unfair advantage or unique positioning identified
- ✅ Opportunity cost considered

**Constraints:**
- ✅ Key assumptions surfaced and marked for testing
- ✅ Scope boundaries clear
- ✅ Riskiest assumption identified

---

**Remember:** This is not a checklist. Use judgment. Pick the 3-5 most important questions for THIS idea. Quality over quantity. The goal is clarity, not completion.

---

## Advanced Techniques

### The "What Would Need to Be True" Framework

Instead of asking "Will this work?", ask:

**"What would need to be true for this to work?"**

This shifts from prediction to assumption surfacing:
- "Customers would need to trust AI for sales outreach"
- "We'd need to achieve 90%+ email deliverability"
- "Sales teams would need to change their workflow"

Then ask: **"How can we test if that's true?"**

This creates a natural path to validation experiments.

### The "Steel Man" Technique

Present the strongest possible version of an opposing view:

**"The strongest argument against this is X. How would you respond?"**

Examples:
- "The strongest argument is that incumbents will copy this in 6 months. What's your response?"
- "Some might say this problem isn't painful enough to pay for. What evidence do you have that it is?"

This tests resilience of thinking and surfaces blind spots.

### The "Second-Order Consequence" Probe

Ask what happens after the first success:

**"If you succeed at this, what happens next?"**

Examples:
- "If you get 10,000 users, what's the next bottleneck?"
- "If customers adopt this, how does their workflow change? What new problems emerge?"

This tests whether the founder has thought beyond the initial win.

---

## Integration with Agent Skills

Map Socratic questions to the 9 validation skills:

**Skill 1: Problem Definition** → Problem Clarity Questions
**Skill 2: Customer Segments** → Problem Clarity + Strategic Fit
**Skill 3: Value Proposition** → Solution Validation
**Skill 4: Solution Overview** → Solution Validation + Constraints
**Skill 5: Market Validation** → Strategic Fit
**Skill 6: Business Model** → Success Criteria + Constraints
**Skill 7: Key Metrics** → Success Criteria
**Skill 8: Risks & Assumptions** → Constraints + All Categories
**Skill 9: Generate Output** → Synthesize all answers

Each skill should incorporate 2-4 Socratic questions tailored to the specific validation area.

---

## Example Full Validation Dialogue

**Idea:** "AI-powered meeting note taker"

**Agent:** "What specific problem does this solve?"
**Founder:** "People forget what was said in meetings."
**Agent:** "How do you know this is a real problem? What evidence do you have?"
**Founder:** "I forget things all the time, and my team complains about it."
**Agent:** "How much time does your team spend trying to remember or find meeting decisions?"
**Founder:** "Probably 2-3 hours a week per person hunting through notes and Slack."
**Agent:** "✓ Specific problem with evidence. Who experiences this most acutely?"
**Founder:** "Remote teams in fast-moving startups."
**Agent:** "How many people on average? What industries?"
**Founder:** "Teams of 10-50 people, mostly tech companies."
**Agent:** "✓ Target segment defined. What do they do today when they have this problem?"
**Founder:** "Assign a note-taker, use Otter.ai, or just wing it and hope for the best."
**Agent:** "Why would they switch from Otter.ai to your solution?"
**Founder:** "Otter just transcribes. We'll extract action items, decisions, and link to project context."
**Agent:** "✓ Differentiation clear. What's the simplest version that solves the core problem?"
**Founder:** "Transcribe, identify action items, send summary."
**Agent:** "What are you NOT doing in V1?"
**Founder:** "No CRM integration, no video recording, no multi-language."
**Agent:** "✓ Scope defined. How will we know if this is successful?"
**Founder:** "Teams use it for every meeting and complete action items faster."
**Agent:** "What metric? What target?"
**Founder:** "80% of meetings processed, 30% reduction in follow-up questions about decisions."
**Agent:** "✓ Success criteria clear. Why are you uniquely positioned to build this?"
**Founder:** "I've built NLP systems for 5 years and understand remote team dynamics."
**Agent:** "✓ Unfair advantage identified. What's the riskiest assumption?"
**Founder:** "That people will trust AI to accurately capture decisions."
**Agent:** "How will you test that?"
**Founder:** "Pilot with 5 teams, show them summaries, ask if they'd rely on it."
**Agent:** "✓ Validation plan clear. Let me summarize before we generate your Lean Canvas..."

[Agent provides summary, founder confirms, canvas generated]

---

**This Socratic framework transforms idea validation from form-filling into rigorous, evidence-based thinking.**
